{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cleaning\n",
    "import augmentation\n",
    "import back_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(\"assignment.csv\")\n",
    "# df.isnull().sum().sum()\n",
    "df_read = df_read.dropna() \n",
    "# df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im struggling to understand how i feel about s...</td>\n",
       "      <td>Emotion</td>\n",
       "      <td>im struggling to understand how i feel about s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new modis promise to ban plastic straws this m...</td>\n",
       "      <td>Financial</td>\n",
       "      <td>new modis promise to ban plastic straws this m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>survey middleincome americans spending less am...</td>\n",
       "      <td>Financial</td>\n",
       "      <td>survey middleincome americans spending less am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watch wall street ended lower after bank stock...</td>\n",
       "      <td>Financial</td>\n",
       "      <td>watch wall street ended lower after bank stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone selling a ton of se puts to open sep a...</td>\n",
       "      <td>Financial</td>\n",
       "      <td>someone selling a ton of se puts to open sep a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content      label  \\\n",
       "0  im struggling to understand how i feel about s...    Emotion   \n",
       "1  new modis promise to ban plastic straws this m...  Financial   \n",
       "2  survey middleincome americans spending less am...  Financial   \n",
       "3  watch wall street ended lower after bank stock...  Financial   \n",
       "4  someone selling a ton of se puts to open sep a...  Financial   \n",
       "\n",
       "                                                name  \n",
       "0  im struggling to understand how i feel about s...  \n",
       "1  new modis promise to ban plastic straws this m...  \n",
       "2  survey middleincome americans spending less am...  \n",
       "3  watch wall street ended lower after bank stock...  \n",
       "4  someone selling a ton of se puts to open sep a...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cleaning.clean_data(df_read)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('content',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English to French to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abir\\anaconda3\\envs\\ai_ml\\lib\\site-packages\\transformers\\generation\\utils.py:1357: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "obj1 = back_translation.back_tr(df,'Sport').main(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = back_translation.back_tr(df,'Science').main(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bt       = pd.concat([df,obj1,obj2],ignore_index=True)\n",
    "df2 = df_bt.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synonym replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Science\n",
    "science_augmentation = augmentation.synonim_aug(df2,multiples=2) \n",
    "science_augmentation['label'] = len(science_augmentation)*['Science']\n",
    "df2 = pd.concat([df2,science_augmentation])\n",
    "\n",
    "#for Sport\n",
    "science_augmentation = augmentation.synonim_aug(df2,class_=\"Sport\",multiples=2) \n",
    "science_augmentation['label'] = len(science_augmentation)*['Sport']\n",
    "df2 = pd.concat([df2,science_augmentation])\n",
    "\n",
    "#stopword removal\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df2['name_stopwords'] = df2['name'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "df2['name_stemming'] = df2['name_stopwords'].apply(lambda x: ' '.join([porter_stemmer.stem(word) for word in x.split() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2[['label','name_stemming']].copy()\n",
    "data.columns = ['label','name']\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['name'],data['label'],test_size=0.2,random_state = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new       = X_train.copy()\n",
    "y_train_new       = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',lowercase=True)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(list(X_train_new))\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abir\\anaconda3\\envs\\ai_ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={'Emotion': 0.9315811965811965,\n",
       "                                 'Financial': 1.1618697367018442,\n",
       "                                 'Health': 0.7182063784923564,\n",
       "                                 'Politics': 0.7095104804061971,\n",
       "                                 'Science': 1.8389573139868398,\n",
       "                                 'Sport': 1.388294484779009},\n",
       "                   max_iter=200)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "clf = LogisticRegression(max_iter=200,class_weight=dict(zip(np.unique(y_train), class_weights)))\n",
    "clf.fit(X_train_tfidf, y_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy is  0.8838532110091744\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"model accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Emotion       0.92      0.89      0.90      2941\n",
      "   Financial       0.84      0.85      0.84      2365\n",
      "      Health       0.91      0.87      0.89      3791\n",
      "    Politics       0.92      0.89      0.90      3840\n",
      "     Science       0.74      0.91      0.82      1477\n",
      "       Sport       0.91      0.91      0.91      1936\n",
      "\n",
      "    accuracy                           0.88     16350\n",
      "   macro avg       0.87      0.89      0.88     16350\n",
      "weighted avg       0.89      0.88      0.88     16350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Detailed Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[12207,   303],\n",
       "        [  428,  3412]],\n",
       "\n",
       "       [[12218,   341],\n",
       "        [  474,  3317]],\n",
       "\n",
       "       [[13178,   231],\n",
       "        [  320,  2621]],\n",
       "\n",
       "       [[13598,   387],\n",
       "        [  361,  2004]],\n",
       "\n",
       "       [[14239,   175],\n",
       "        [  179,  1757]],\n",
       "\n",
       "       [[14411,   462],\n",
       "        [  137,  1340]]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_test, y_pred, labels=[\"Politics\",\"Health\",\"Emotion\",\"Financial\",\"Sport\",\"Science\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of probable classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test_tfidf)\n",
    "top3_indices = y_pred_proba.argsort(axis=1)[:,-3:]\n",
    "top_classes = clf.classes_[top3_indices]\n",
    "top3_probs = y_pred_proba[np.arange(y_pred_proba.shape[0])[:,None],top3_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_test = df2.loc[X_test.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement:i looked her deeply in the eyes and expressed to her that i loved her so deeply and that what she perceived as anger was my frustration at feeling inadequate to take care of her\n",
      "Top 3 predicted classes:\n",
      "Politics - Probability: 0.0005878887552105808\n",
      "\n",
      "Health - Probability: 0.005741466412437277\n",
      "\n",
      "Emotion - Probability: 0.9923549344538236\n",
      "\n",
      "Statement:there are over 14 million active voters in the statenevada secretary of state says 21 noncitizens could have voted for president in her state\n",
      "Top 3 predicted classes:\n",
      "Sport - Probability: 0.0012677182786973266\n",
      "\n",
      "Financial - Probability: 0.015711154416931092\n",
      "\n",
      "Politics - Probability: 0.9813437943899106\n",
      "\n",
      "Statement:italy extends cut on fuel excise duties to aug 21st from aug 2nd\n",
      "Top 3 predicted classes:\n",
      "Sport - Probability: 0.05723622138795872\n",
      "\n",
      "Science - Probability: 0.06521681179053203\n",
      "\n",
      "Financial - Probability: 0.7894328043342379\n",
      "\n",
      "Statement:i wept with my grandparents who prayed for me by phone that i would feel gods presence to which i replied that i felt so punished\n",
      "Top 3 predicted classes:\n",
      "Health - Probability: 0.009405530381991625\n",
      "\n",
      "Politics - Probability: 0.01594605029120165\n",
      "\n",
      "Emotion - Probability: 0.9563815107628605\n",
      "\n",
      "Statement:mysterious light seen near huge black hole\n",
      "Top 3 predicted classes:\n",
      "Health - Probability: 0.015298136022213015\n",
      "\n",
      "Politics - Probability: 0.031028485842551596\n",
      "\n",
      "Science - Probability: 0.9220756295866963\n",
      "\n",
      "Statement:pak testfires nuclear equal_to ballistic projectile shaheen 1a\n",
      "Top 3 predicted classes:\n",
      "Sport - Probability: 0.0014193512996548985\n",
      "\n",
      "Science - Probability: 0.006046041627919997\n",
      "\n",
      "Financial - Probability: 0.9896911839721735\n",
      "\n",
      "Statement:deoxyadenosine_monophosphate guide for meter writerssources kevin William_James_Durant interest In your crappy team here\n",
      "Top 3 predicted classes:\n",
      "Politics - Probability: 0.05302234095972183\n",
      "\n",
      "Science - Probability: 0.4088409417364434\n",
      "\n",
      "Sport - Probability: 0.4689038652865989\n",
      "\n",
      "Statement:nvos 143 pre novo integrated sciences announces preliminary revenue range for fiscal 2022 third quarter\n",
      "Top 3 predicted classes:\n",
      "Financial - Probability: 0.041064671202605325\n",
      "\n",
      "Sport - Probability: 0.05158776419561096\n",
      "\n",
      "Politics - Probability: 0.8346615459352483\n",
      "\n",
      "Statement:last august the 30yearold chinese star hired rodriguez who coached justine henin to seven grand slam titles after the conflicts with her previous coach her husband jiang shan became too much to bear the funny thing is i think two years ago in china someone said i was divorced li said tuesday after beating polands agnieszka radwanska 75 63 to advance to the semifinals of the australian open against maria sharapova because they were thinking were always shouting maybe were divorced its just being coach and husband is how you say tough to find a balance she added now li and jiang have found marital peace again fewer disagreements on or off the court and she is winning again li hired rodriguez after disappointing earlyround losses at wimbledon and the london olympics he joined her midweek at a tournament in cincinnati they had never even met before and she captured the title her first since her breakthrough grand slam win at roland garros in 2011 she then won a second title at the inaugural shenzhen open earlier this month and is now in the semifinals of the australian open for the third time in four years rodriguez has had a steadying influence on li who had previously struggled to control her emotions on court and has appeared more composed since starting to work with him at one point during the second set against radwanska li lost her service toss in the sun and batted the ball five rows deep into the crowd rather than let the misshit unnerve her however she calmly made her second serve and put away a deft backhand volley to win the point i was working a lot on this aspect in winter training li said carlos always say calm down calm down in interviews she seems happier as well two years ago on her way to becoming the first chinese player to reach a grand slam final at the australian open li was pure entertainment in her press conferences joking about her husbands snoring and admitting she forget her own wedding anniversary after her win at the french open however things changed she began to put more pressure on herself at the grand slams and didnt make a quarterfinal at six consecutive majors at last years australian open she left in tears after wasting four match points in the fourth round against kim clijsters on tuesday li said she was still thinking about those match points a year later during her thirdround match against romanian sorana cirstea when i was playing cirstea in rod laver i was thinking about the match last year its something you couldnt forget always in your mind she said this year though she says she is more relaxed and shes back to her humorous self when asked during her postmatch interview what happened with that very wayward serve she quipped i want to have good communication with the fans then she said to her coach carlos make sure we practice on serve later li related the difficulties she had when she started training with rodriguez at the spaniards tennis academy in beijing after three days of sixhour workouts she called her husband in distress after three days i was dying because my husband didnt come with me to beijing i called him and said carlos is crazy she said jiang didnt believe her so he came to beijing to see for himself i was doing some exercises with carlos jiang was sitting in the gym li said after i was halfway done he was like are you finished i said no only halfway he said im tired i said dont say that im doing exercises youre only sitting dont say youre tired li admits now the hard work was worth it her fitness was tested against the fourthseeded radwanska a crafty player who relies on spins and slices to construct points and wears her opponents down with her consistency radwanska tried to dictate play by moving li around the court but the chinese sixth seed countered with deep heavy groundstrokes and superb volleying winning 20 of 24 points at net some of the games she didnt let me do anything radwanska said after the match i think shes a very consistent player shes always playing on the same level its not like up and down like the other girls li will next play no 2ranked sharapova who said she can also see a difference in lis game since shes been working with rodriguez shes a grand slam champion it wasnt like she needed someone to come in and fix her game she said but sometimes when you just have a different surrounding and a new voice they might be saying the same things but it just gets to you a little bit differently and your motivation changes li knows she will have to be sharp against sharapova the russian won the three matches they played last year and owns an 84 headtohead record against li but she believes shes a stronger player this year im getting a little bit older getting more experience li said right now i really enjoy every match\n",
      "Top 3 predicted classes:\n",
      "Emotion - Probability: 0.037295121413854146\n",
      "\n",
      "Health - Probability: 0.049067851291417594\n",
      "\n",
      "Sport - Probability: 0.8145701643971622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(f\"Statement:{df2_test.iloc[i]['name']}\")\n",
    "    print(\"Top 3 predicted classes:\")\n",
    "    for j in range(3):\n",
    "        print(f\"{top_classes[i][j]} - Probability: {top3_probs[i][j]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                                                       Emotion\n",
       "name              i looked her deeply in the eyes and expressed ...\n",
       "name_stopwords    looked deeply eyes expressed loved deeply perc...\n",
       "name_stemming     look deepli eye express love deepli perceiv an...\n",
       "Name: 15243, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
